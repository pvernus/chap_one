---
title: 'Magnitude'
format: html
editor: visual
---

```{r load_pckg, include=FALSE, cache=FALSE}

source(here::here('scripts', 'library.R'))
```

# Hazard severity (S)

## Extreme weather events

### Wet

```{r import_wet}

# define the directory
data_path <- "C:\\Users\\pauvernu\\Seafile\\library\\chap_one_data\\source\\treatment\\mswep\\wet"

# define the file pattern
files <- list.files(data_path, full.names = TRUE)

# import and arrange dta files
data_list <- lapply(files, function(file) {
  # read file
  data <- haven::read_dta(file)
  file_name <- basename(file)
  # rename variable
  names(data) <- ifelse(grepl("^p", names(data)), "value", names(data))
   # create indice variable
  if (grepl("rx1d", file_name)) {
    data$indice <- "rx1d"
  } else if (grepl("rx5d", file_name)) {
    data$indice <- "rx5d"
  }
  # create percentile variable
  if (grepl("p90", file_name)) {
    data$percentile <- "p90"
  } else if (grepl("p95", file_name)) {
    data$percentile <- "p95"
  } else if (grepl("p99", file_name)) {
    data$percentile <- "p99"
  }
  
  return(data)
})

# rename list objects
names(data_list) <- sapply(basename(files), function(x) {
  x <- sub("^geo_id_", "", x)
  sub("\\.dta$", "", x)
})

# combine list elements
data_wet <- do.call(rbind, data_list)

## remove useless objects
rm(data_list)
```

### Dry

```{r import_dry}

# define the directory
data_path <- "C:\\Users\\pauvernu\\Seafile\\library\\chap_one_data\\source\\treatment\\mswep\\dry"

# define the file pattern
files <- list.files(data_path, full.names = TRUE)

# import and arrange dta files
data_list <- lapply(files, function(file) {
  # read file
  data <- haven::read_dta(file)
  file_name <- basename(file)
  # rename variable
  names(data) <- ifelse(grepl("^p", names(data)), "value", names(data))  
   # create indice variable
  if (grepl("rx90d", file_name)) {
    data$indice <- "rx90d"
  } else if (grepl("rx180d", file_name)) {
    data$indice <- "rx180d"
  }
  # create percentile variable
  if (grepl("p10", file_name)) {
    data$percentile <- "p10"
  } else if (grepl("p5", file_name)) {
    data$percentile <- "p5"
  } else if (grepl("p1", file_name)) {
    data$percentile <- "p1"
  }

  return(data)
})

# rename list objects
names(data_list) <- sapply(basename(files), function(x) {
  x <- sub("^geo_id_", "", x)
  sub("\\.dta$", "", x)
})

# combine list elements
data_dry <- do.call(rbind, data_list)

## remove useless objects
rm(data_list)
```

### Hot

```{r import_hot}

# define the directory
data_path <- "C:\\Users\\pauvernu\\Seafile\\library\\chap_one_data\\source\\treatment\\era5\\temperature"

# define the file pattern
files <- list.files(data_path, full.names = TRUE)

# import and arrange dta files
data_list <- lapply(files, function(file) {
  # read file
  data <- haven::read_dta(file)
  file_name <- basename(file)
  # rename variable
  names(data) <- ifelse(grepl("^p", names(data)), "value", names(data))  
   # create indice variable
  if (grepl("tmax1d", file_name)) {
    data$indice <- "tmax1d"
  } else if (grepl("tmax5d", file_name)) {
    data$indice <- "tmax5d"
  }
  # create percentile variable
  if (grepl("p90", file_name)) {
    data$percentile <- "p90"
  } else if (grepl("p95", file_name)) {
    data$percentile <- "p95"
  } else if (grepl("p99", file_name)) {
    data$percentile <- "p99"
  }

  return(data)
})

# rename list objects
names(data_list) <- sapply(basename(files), function(x) {
  x <- sub("^geo_id_", "", x)
  sub("\\.dta$", "", x)
})

# combine list elements
data_hot <- do.call(rbind, data_list)

## remove useless objects
rm(data_list)
```

### Wind

```{r import_wind}

# define the directory
data_path <- "C:\\Users\\pauvernu\\Seafile\\library\\chap_one_data\\source\\treatment\\era5\\wind"

# define the file pattern
files <- list.files(data_path, full.names = TRUE)

# import and arrange dta files
data_list <- lapply(files, function(file) {
  # read file
  data <- haven::read_dta(file)
  file_name <- basename(file)
  # rename variable
  names(data) <- ifelse(grepl("^p", names(data)), "value", names(data))  
   # create indice variable
  data$indice <- "wmean1d"
  # create percentile variable
  if (grepl("p90", file_name)) {
    data$percentile <- "p90"
  } else if (grepl("p95", file_name)) {
    data$percentile <- "p95"
  } else if (grepl("p99", file_name)) {
    data$percentile <- "p99"
  }
  
  return(data)
})

# rename list objects
names(data_list) <- sapply(basename(files), function(x) {
  x <- sub("^geo_id_", "", x)
  sub("\\.dta$", "", x)
})

# combine list elements
data_wind <- do.call(rbind, data_list)

## remove useless objects
rm(data_list)
```

### All

```{r data_clim}

# create list
list_clim <- list(data_wet, data_dry, data_hot, data_wind)
# combine list elements
data_clim <- do.call(rbind, list_clim)

# create variables 
data_clim <- data_clim |> 
  mutate(
    threshold = case_when(
      percentile == "p1" | percentile == "p99" ~ 3.65,
      percentile == "p5" | percentile == "p95" ~ 18.25,
      percentile == "p10" | percentile == "p90" ~ 36.5),
    extreme = ifelse(value >= threshold, 1, 0),
    year = as.double(year),
    percentile = factor(percentile, levels=c("p1", "p5", "p10", "p90", "p95", "p99"))
    )

# modify labels
labelled::var_label(data_clim$value) <- "(mean)"

# summary
summary(data_clim)
```
```{r}
# save
save(data_wet, data_dry, data_hot, data_wind, data_clim,
     file = "C:\\Users\\pauvernu\\Seafile\\library\\chap_one_data\\data\\treatment\\data_clim.RData")
```

```{r}

## facet by indice
# mean value
summarize(data_clim,
          mean_value = mean(value),
          .by = c(year, indice)) |> 
  filter(year <= 2018) |> 
  ggplot(aes(x = year, y = mean_value)) +
  geom_line() +
  geom_smooth(method=lm) +
  facet_wrap(~indice) +
  theme_light() +
  labs(
    x = "",
    y = "Mean days > threshold"
  )

# mean extreme
# Define the color palette
color_palette <- c("p1" = "#E91300", "p99" = "#E91300",
                   "p5" = "#FF912F", "p95" = "#FF912F",
                   "p10" = "#FFD17A", "p90" = "#FFD17A")
# plot
summarize(data_clim,
          mean_extr = mean(extreme),
          .by = c(year, indice, percentile)) |> 
  filter(year <= 2018) |> 
  ggplot(aes(x = year, y = mean_extr, color = percentile)) +
  geom_line() +
  geom_smooth(method=lm, se = FALSE) +
  scale_color_manual(values = color_palette) +
  facet_wrap(~indice) +
  theme_light() +
  labs(
    x = "",
    y = "Proportion of extreme events (days > threshold)"
  )

```

## Disaster events

```{r load}

# Load datasets
load(file = "C:\\Users\\pauvernu\\Seafile\\library\\chap_one_data\\data\\treatment\\emdat\\data_emdat.RData") # EM-DAT
load(file = file = "C:\\Users\\pauvernu\\Seafile\\library\\chap_one_data\\data\\treatment\\data_gdis.RData") # GDIS
```

### EM-DAT

```{r clean_emdat}

## EMDAT
data_emdat_short <- data_emdat |> 
  select(dis_no, classification_key, disaster_type, iso, country, location, start_year, end_year, last_update) |> 
  filter(start_year %in% 2000:2018) |> # time period
  filter(grepl('nat-hyd-flo|nat-cli-dro|nat-met-sto|nat-met-ext-hea', classification_key)) |> # disaster type
  mutate(disasterno = stringr::str_sub(dis_no, end = -5)) |> 
  mutate(iso3c = countrycode(sourcevar = country,
                             origin = 'country.name',
                             destination = 'iso3c'
  )) |> 
  mutate(iso3c = case_when(
# NOTE: Canary Islands
    country == "Canary Islands" ~ "ESP",
# NOTE: Serbia Montenegro (iso==SCG)
# In variable 'location', we can find the name of one of the two countries at the end of the character string. I assume that it provides the true location.
    iso == "SCG" & grepl("Serbia)$", str_squish(location)) ~ "SRB",
    iso == "SCG" & grepl("Montenegro)$", str_squish(location)) ~ "MNE",
# NOTE: Kosovo
# Some obs. are located in Kosovo in GDIS, but in Serbia in EMDAT
# Kosovo is included in OECD CRS since 2009 (declaration of independence in 2008)
# Rule: if year < 2009 => Serbia (SRB) & if year >= 2009 => Kosovo (XKX)
# In EMDAT, two obs. don't apply to this rule
    dis_no %in% c("2013-0379-SRB", "2016-0446-SRB") ~ "XKX",
# NOTE South Sudan: 
# South Sudan is included in OECD CRS since 2011 (independent State in 2011)
# Rule: if year < 2011 => Sudan (SDN) & if year >= 2011 => South Sudan (SSD)
    country=='South Sudan' & start_year >= 2011 ~ 'SSD',
    country=='South Sudan' & start_year < 2011 ~ 'SDN',
    .default = iso3c
         )) |> 
# NOTE: duplicated obs. dis_n=="2010-0579" with two different location
# dis_no == "2010-0579-SDN": entry_date==2011; country=="Sudan") / 
# dis_no == "2010-0579-SSD": entry_date==2016; country=="South Sudan"
# I keep the observation which follows the rule set above  
  filter(dis_no != "2010-0579-SSD")

```

### GDIS

```{r clean_gdis}

## GDIS
data_gdis <- sf::st_set_geometry(GDIS_disasterlocations, NULL) # remove geometry
data_gdis_short <- data_gdis |> 
  select(disasterno, dis_id = id, geo_id, disastertype, iso3, country) |> 
  mutate(year = as.numeric(substr(data_gdis$disasterno, 1, 4))) |> # time period
  filter(year >= 2000) |> 
  mutate(disastertype = trimws(disastertype)) |> # disaster type
  filter(disastertype %in% c('flood', 'drought', 'storm', 'extreme temperature')) |> 
  mutate(iso3c = countrycode(sourcevar = country,
                             origin = 'country.name',
                             destination = 'iso3c'
  )) |> 
  mutate(iso3c = case_when(
# Micronesia    
    country=='Micronesia' ~ 'FSM',
# NOTE Kosovo: same rule as for EMDAT
    country=='Kosovo' & year >= 2009 ~ 'XKX',
    country=='Kosovo' & year < 2009 ~ 'SRB',
# NOTE South Sudan: same rule as for EMDAT
    country=='South Sudan' & year >= 2011 ~ 'SSD',
    country=='South Sudan' & year < 2011 ~ 'SDN',
    .default = iso3c
    )) |> 
# NOTE: UKR/Crimea:
# disasterno=='2002-0482': three obs. in GDIS incl. one in Crimea/UKR (geo_id==22653) != RUS in EMDAT
# For now, I remove the UKR obs. geo_id
  filter(geo_id != 22653)

```

```{r compare_data}

## compare nb of events
length(unique(data_gdis_short$disasterno))
length(unique(data_emdat_short$disasterno))

## events in gdis, missing in emdat
anti_join(distinct(data_gdis_short, disasterno, disastertype),
          distinct(data_emdat_short, disasterno),
          by = "disasterno")
# NOTE: 163 events in GDIS w/out a match in EMDAT

## events in emdat, missing in gdis
anti_join(distinct(data_emdat_short, disasterno, disaster_type),
          distinct(data_gdis_short, disasterno),
          by = "disasterno")
# NOTE: 246 events in EMDAT w/out a match in GDIS

# Not sure why.
# Some events missing in EMDAT are due to *cold* extreme temperature events. GDIS does not differentiate between hot and cold extreme temperature.
# Note that EMDAT has been updated regularly *after* GDIS publication. So maybe missing events are due to deleted/added/modified event that have occurred following an update.
```

```{r compare_data_freq}

year_event_emdat = data_emdat_short |> 
  select(disaster_type, year = start_year, disasterno) |> 
  summarize(n = length(unique(disasterno)),
           .by = c(year, disaster_type)) |> 
  mutate(source = "emdat",
         disaster_type = tolower(disaster_type))

year_event_gdis = data_gdis_short |> 
  select(disaster_type = disastertype, year, disasterno) |> 
  summarize(n = length(unique(disasterno)),
           .by = c(year, disaster_type)) |> 
  mutate(source = "gdis")

year_event = rbind(year_event_emdat, year_event_gdis)

ggplot(year_event, aes(x = year, y = n, color = source)) +
  geom_line() + 
  facet_wrap(~ disaster_type, scales = "free_y") +
  theme_light() +
  labs(y = "Frequency")
```

```{r join_gdis_emdat}

emdat = data_emdat_short |> 
  select(disasterno, disaster_type, country, iso3c, start_year, end_year) |> 
  mutate(disaster_type = tolower(disaster_type))

gdis = data_gdis_short |> 
  select(disasterno, disaster_type = disastertype, country, iso3c, year, geo_id)

# merge
join_gdis_emdat <- left_join(gdis, emdat, 
                             by = c('disasterno', 'iso3c'), 
                             suffix = c('_gdis', '_emdat'))

# difference in disaster type classification
join_gdis_emdat |> 
  filter(disaster_type_gdis != disaster_type_emdat)
# NOTE: not an issue. Only one event in Italy (Storm/Flood)

# difference in year
join_gdis_emdat |> 
  filter(year < start_year | year > end_year)
# NOTE: five events where different specified year between EMDAT and GDIS. For all of them, GDIS event starts one year before same EMDAT event.

# Missing data
join_gdis_emdat |> 
  filter(is.na(disasterno))
```

```{r save}

save(join_gdis_emdat, file = "C:\\Users\\pauvernu\\Seafile\\library\\chap_one_data\\data\\treatment\\join_gdis_emdat.RData")
```

## Merge weather-disaster events

```{r data_severity}

data_severity <- left_join(data_clim, join_gdis_emdat,
          by = "geo_id",
          suffix = c('', '_dis'))

# CHECK: object should have the same number of obs. as data_prec
length(unique((data_severity$geo_id)))
length(unique((data_clim$geo_id)))
```

### 

```{r}

df <- data_severity |> 
  mutate(dis_dummy = ifelse(year == year_dis, 1, 0),
         dis_reltime = year - year_dis)

df |> 
  filter(dis_reltime %in% c(-5:5)) |> 
  tabyl(extreme, dis_reltime) |> 
  cprop()

df |> 
  filter(dis_reltime %in% c(-5:5)) |> 
  summarize(prop = sum(extreme)/length(extreme), .by = c(dis_reltime, indice)) |> 
  ggplot(aes(x=factor(dis_reltime), y=prop)) +
  geom_bar(stat = "identity") + 
  scale_y_continuous(labels = scales::percent) +
  facet_wrap(~indice) + 
  gghighlight::gghighlight(dis_reltime==0, calculate_per_facet = TRUE) +
  theme_light() + 
  labs(x = "Relative time to GDIS disaster year",
       y = "Share of 'extreme' years")

```

# Hazard exposure (E)

## Landscan (pop)

```{r data_landscan}

# Define the folder path containing the .xlsx files
folder_path <- here('source', 'treatment', 'landscan')

# List all files in the folder with the specified pattern
files <- list.files(path = folder_path, pattern = 'landscan_flood_\\d{4}\\.xlsx', full.names = TRUE)

# Function to read files and add year column
process_file <- function(file_path) {
  # Extract the year from the file name
  year <- str_extract(file_path, '(?<=landscan_flood_)\\d{4}') %>% as.numeric()
  
  # Validate the year range
  if (year %in% 2001:2022) {
    # Read the Excel file
    data <- read_excel(file_path, col_types = c('numeric', 'numeric', 'text', 
        'text', 'text', 'text', 'numeric', 
        'text', 'text', 'text', 'text', 'text', 
        'text', 'numeric', 'text', 'text', 
        'text', 'numeric', 'text', 'numeric', 
        'text', 'numeric', 'numeric', 'numeric'))
    # Add the year column
    data <- data |> 
      janitor::clean_names() |> 
      mutate(year = year) |> 
      rename_with(~ gsub('^pop_.*', 'pop', .), starts_with('pop_'))
    return(data)
  }
  return(NULL) # Return NULL for invalid years
}

# Process all files and combine the results
data_landscan <- files |> 
  lapply(process_file) |>       # Apply the processing function
  compact() |>                  # Remove NULLs from the list
  bind_rows()                   # Combine all data frames into one

```

```{r data_landscan_short}

## NOTE: measurement errors
# population estimations can vary widely from one year to another
# I compute trailing moving averages (k=3) to smooth pop estimations

data_landscan_short <- subset(data_landscan,
  select = c(geo_id, year, disasterno, pop)) |> 
  group_by(geo_id) |> 
  mutate(pop_tma = zoo::rollmean(pop, k = 3, fill = NA, align = "right")) |> 
# due to k=3, missing pop data in before 2003
  filter(year >= 2003) |> 
  pivot_longer(
    cols = starts_with("pop"),
    names_to = "pop",
    values_to = "pop_value") |> 
  ungroup() |> 
  arrange(geo_id)

head(data_landscan_short)
```

## Modis (land cover)

```{r data_modis}

# Define the folder path containing the .xlsx files
folder_path <- here('source', 'treatment', 'modis')

# List all files in the folder with the specified pattern
files <- list.files(path = folder_path, pattern = '*.xlsx', full.names = TRUE)

# Function to read files and add year column
process_file <- function(file_path) {
  # Extract the year from the file name
  year <- str_extract(file_path, '(?<=modis_flood_)\\d{4}') |> as.numeric()
  
  # Validate the year range
  if (year %in% 2001:2022) {
    # Read the Excel file
    data <- read_excel(file_path)
    # Add the year column
    data <- data |> 
      janitor::clean_names() |> 
      mutate(year = year)
  }
  else {
    NULL # Return NULL for invalid years
  }
}

# Process all files and combine the results
data_modis <- files |> 
  lapply(process_file) |> # Apply the processing function
  compact() |> # Remove NULLs from the list (requires `purrr` library or alternative filtering)
  bind_rows() # Combine all data frames into one

```

```{r data_modis_short}

## Land cover classification
# see: https://modis-land.gsfc.nasa.gov/pdf/MCD12Q1_C6_Userguide04042018.pdf

# Croplands: 12
# Cropland/Natural Vegetation Mosaics: 14
# Urban and Built-up Lands: 13

data_modis_short <- data_modis |> 
  mutate(land_crop = c_12 + c_14,
         land_urb = c_13) |> 
  dplyr::select(geo_id, year, disasterno, starts_with("land")) |> 
  pivot_longer(
    cols = starts_with("land"),
    names_to = "land",
    values_to = "land_value") |> 
  arrange(geo_id)
    
head(data_modis_short)
```

# Hazard magnitude (M)

```{r}

## Compare length between landscan and modis datasets
# disasterno
length(unique(data_landscan_short$disasterno))
length(unique(data_modis_short$disasterno))
# geo_id
length(unique(data_landscan_short$geo_id))
length(unique(data_modis_short$geo_id))

# NOTE: LANDSCAN has less observations than MODIS because we removed years 2001-2002 after computing 3y-trailing moving averages of pop. estimates

## Landscan
# disasterno in landscan but missing in emdat/gdis
anti_join(distinct(data_landscan_short, disasterno), 
          distinct(data_severity, disasterno), 
          by = "disasterno")

# geo_id in landscan but missing in emdat/gdis
anti_join(distinct(data_landscan_short, geo_id, disasterno), 
          distinct(data_severity, geo_id, disasterno), 
          by = "geo_id")
# geo_id in emdat/gdis but missing in landscan
anti_join(distinct(data_severity, geo_id, disasterno), 
          distinct(data_landscan_short, geo_id, disasterno), 
          by = "geo_id")

## MODIS
# disasterno in modis but missing in emdat/gdis
anti_join(distinct(data_modis_short, disasterno), 
          distinct(data_severity, disasterno), 
          by = "disasterno")

# geo_id in modis but missing in emdat/gdis
anti_join(distinct(data_modis_short, geo_id, disasterno), 
          distinct(data_severity, geo_id, disasterno), 
          by = "geo_id")
# geo_id in emdat/gdis but missing in modis
anti_join(distinct(data_severity, geo_id, disasterno), 
          distinct(data_modis_short, geo_id, disasterno), 
          by = "geo_id")

# TO DO: check why we don't get the same number of distinct observations
# anti_join(data_severity, data_landscan, by = c("geo_id", "year"))
# anti_join(data_landscan, data_severity, by = c("geo_id", "year"))
```

```{r data_exposure}

# merge landscan (population) and modis (landuse)
data_exposure <- merge(data_landscan_short, data_modis_short, 
      by = c("geo_id", "disasterno", "year"))

```

```{r data_magnitude}

# merge severity and exposure data
data_magnitude <- merge(data_exposure, data_severity, 
      by = c("geo_id", "disasterno", "year")) |> 
  dplyr::select(geo_id, disasterno, iso3c, year, year_dis, classification_key,
                starts_with("prec"),
                starts_with("pop"),
                starts_with("land"))

data_magnitude |> 
  group_by(prec) |> 
  summary(prec_value)

summarize(data_magnitude,
  min = min(land_value),
  max = max(land_value),
  .by = land
)
```

```{r distribution_value}

# Precipitation
data_magnitude |>  
  filter(year == year_dis) |>
  mutate(mean = mean(prec_value)) |> 
  ggplot(aes(x=prec_value)) +
  geom_density() +
  geom_vline(aes(xintercept = mean), linetype = "dashed", colour = "blue") +
  theme_light()

# Population
data_magnitude |>  
  filter(year == year_dis) |>
  mutate(mean = mean(pop_value)) |> 
  ggplot(aes(x=pop_value)) +
  geom_density() +
  geom_vline(aes(xintercept = mean), linetype = "dashed", colour = "blue") +
  theme_light()

# Land
data_magnitude |>  
  filter(year == year_dis) |>
  mutate(mean = mean(land_value)) |> 
  ggplot(aes(x=land_value)) +
  geom_density() +
  geom_vline(aes(xintercept = mean), linetype = "dashed", colour = "blue") +
  theme_light()
```

```{r data_rank}

data_rank <- data_magnitude |>  
# keep treated years only  
  filter(year == year_dis) |> 
# percentile rank severity and exposure vars
  group_by(prec, pop, land) |>   
  mutate(rank_prec = percent_rank(prec_value)) |> # severity
  mutate(rank_pop = percent_rank(pop_value)) |>  # exposure (pop)
  mutate(rank_land = percent_rank(land_value)) |> # exposure (land)
  ungroup() |> 
## create percentile rank dummies
# exposure
  mutate(
    p50_pop_dummy = ifelse(rank_pop >= .5, 1, 0),
    p4060_pop_dummy = ifelse(rank_pop >= .4 & rank_prec <= .6, 1, 0),
    p90_pop_dummy = ifelse(rank_pop >= .9, 1, 0),
    p99_pop_dummy = ifelse(rank_pop >= .99, 1, 0)      
  ) |> 
# severity
  mutate(
    p50_prec_dummy = ifelse(rank_prec >= .5, 1, 0),
    p4060_prec_dummy = ifelse(rank_prec >= .4 & rank_prec <= .6, 1, 0),
    p90_prec_dummy = ifelse(rank_prec >= .9, 1, 0),
    p99_prec_dummy = ifelse(rank_prec >= .99, 1, 0)
  )
```

```{r data_unit}

data_unit <- data_rank |> 
  expand(iso3c, year)
```

```{r data_sd2_pop}

data_sd2_pop <- data_rank |> 
  filter(prec=="sd2") |> # severity index
  filter(pop=="pop_tma") |> # exposure index
  dplyr::select(geo_id, iso3c, year, contains("prec_dummy"), contains("pop_dummy")) |> 
  summarize(
# exposure
    D_pop_50 =  ifelse(sum(p50_pop_dummy) > 0, 1, 0),
    D_pop_4060 = ifelse(sum(p4060_pop_dummy) > 0, 1, 0),
    D_pop_90 =  ifelse(sum(p90_pop_dummy) > 0, 1, 0),
    D_pop_99 = ifelse(sum(p99_pop_dummy) > 0, 1, 0),
# severity
    D_prec_50 = ifelse(sum(p50_prec_dummy) > 0, 1, 0),
    D_prec_4060 = ifelse(sum(p4060_prec_dummy) > 0, 1, 0),
    D_prec_90 = ifelse(sum(p90_prec_dummy) > 0, 1, 0),
    D_prec_99 = ifelse(sum(p99_prec_dummy) > 0, 1, 0),
    .by = c("iso3c", "year")) |> 
  arrange(iso3c, year)
```

```{r treatment}

treatment <- left_join(data_unit, data_sd2_pop, by = c("iso3c", "year")) |> 
  mutate(across(starts_with("D_"), \(x) replace_na(x, 0)))
```

```{r}

save(treatment, file = here("data", "data_magnitude.RData"))
```

```{r}
rm(data_emdat, data_exposure, data_gdis, data_landscan, data_modis, key_emdat, GDIS_disasterlocations)
```
